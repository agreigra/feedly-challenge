{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Graph implementation\n",
    "\n",
    "In this notebook I have implemented my own classes to represent a graph and its components and other functions necessery for processing a text.<br>\n",
    "A graph consists of nodes that may or may not be connected via edges. There are two easy ways to implement it in python using an adjacency list or an adjacency matrix. In this case, I have used an adjacency list because many operations are less expensive in term of complexity on this type data structure. Yet, I have added function which can transform adjacency list to an adjacency matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important points in the implementation: \n",
    "\n",
    "### Complexity of building the graph\n",
    "\n",
    "- Assuming that we have a dataset containing N samples, building a graph with this dataset can be done in 2 steps:\n",
    "    1. Creating a node for each sample by iterating through the dataset which will take exactly ***O(N)*** time.\n",
    "    2. Adding edges between the nodes of the graph assuming that two nodes are connected if they share at least n tokens. Since the graph is undirected, this will take only ***O(N.log(N))*** time ignoring the time we spend computing the number of shared tokens. \n",
    "    \n",
    "### complexity of finding all connected components\n",
    "  \n",
    "- To find the component of a given graph there is many ways to do it. Here, I have implemented as follow:\n",
    "    1.  I start by initializing all the nodes as not visited. Then I iterate through all nodes, and each time I chech if the node is yet visited or not. If it wasn't visited, I call the DFS function.\n",
    "    2. DFS is an implementation of the Depth-First Search algorithm. In each iteration of the for loop, it adds this node to the current component and explores their neighbors in a recurring manner.\n",
    "    \n",
    "    \n",
    "This Algorithm take also ***O(N + $\\epsilon$)*** time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph(object):\n",
    "    \"\"\"\n",
    "    A class used to represent a graph\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    nodes : dictionary\n",
    "        used to store the nodes of the graph\n",
    "    nodesNumber : int\n",
    "        number of nodes in the graph\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    add_node(node)\n",
    "        adds new node to the graph\n",
    "    \n",
    "    add_edge(node1, node2)\n",
    "        adds edges between node1 and node1  \n",
    "    \n",
    "    add_edges(n)\n",
    "        adds the edges between each two nodes\n",
    "        if they share at least n tokens\n",
    "    \n",
    "    get_nodes()\n",
    "        returns the list of nodes in the graph\n",
    "    \n",
    "    samples(n=10)\n",
    "        print n random nodes with their edges\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\" initializes a graph object\n",
    "        as an empty dictionary\n",
    "        \"\"\"\n",
    "        self.nodes = {}\n",
    "        self.nodesNumber = 0\n",
    "        self.connectedComponents = None\n",
    "        \n",
    "    def add_node(self, node):\n",
    "        \"\"\" Adds a new node to the graph\n",
    "        if doesn't exist already\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node : node\n",
    "            the object node to add\n",
    "        \"\"\"\n",
    "        if node in self.nodes:\n",
    "            print(\"node \", node, \" already exists in the graph\")\n",
    "        else:\n",
    "            self.nodes[node.id] = node\n",
    "            self.nodesNumber +=1\n",
    "            \n",
    "    def add_edge(self, node1, node2, weight):\n",
    "        \"\"\" Adds an edge between node1 and node2\n",
    "        if both exist in the graph\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node1: node\n",
    "        node2: node\n",
    "        \"\"\"\n",
    "        if node1 not in self.nodes:\n",
    "            print(\"node \", node1.id, \" doesn't exist in the graph\")\n",
    "        \n",
    "        elif node2 not in self.nodes:\n",
    "            print(\"node \", node2.id, \" doesn't exist in the graph\")\n",
    "        \n",
    "        else:\n",
    "            self.nodes[node1].edges[node2] = weight\n",
    "            self.nodes[node2].edges[node1] = weight\n",
    "    \n",
    "    \n",
    "    def add_edges(self, n):\n",
    "        \"\"\"Adds adges bewteen each two nodes of the graph\n",
    "        if they share at least n tokens\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n : int\n",
    "            Number of tokens that each two nodes\n",
    "            should share two have a link between them\n",
    "        \"\"\"\n",
    "        nodes = list(self.nodes.keys())\n",
    "        for i in range(len(nodes)):\n",
    "            for j in range(i, len(nodes)):\n",
    "                number_shared_tokens = intersection(self.nodes[i], self.nodes[j])\n",
    "                if (i!=j) and (number_shared_tokens >= n):\n",
    "                    self.add_edge(i, j, number_shared_tokens)\n",
    "    \n",
    "    def get_nodes(self):\n",
    "        \"\"\" returns the list of the \n",
    "            nodes exist in the graph\n",
    "        \"\"\"\n",
    "        return list(self.nodes.keys())\n",
    "    \n",
    "    def samples(self, n=10):\n",
    "        \"\"\"Prints n random nodes form the graph.\n",
    "        If the argument n isn't passed in, the \n",
    "        default value\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n : int, optional\n",
    "            Number of samples to print (default is 10)\n",
    "        \"\"\"\n",
    "        graph = \"{\"\n",
    "        samples = choices(list(self.nodes.keys()), k = n)\n",
    "        for i in samples:\n",
    "            graph += str(self.nodes[i])+\"\\n\"\n",
    "        graph += \"}\"\n",
    "        print(graph)\n",
    "    \n",
    "\n",
    "    def connected_components(self):\n",
    "        \"\"\"Finds the connected components in the graph\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        components: list of lists\n",
    "            each sub-list represents a connected component\n",
    "        \n",
    "        \"\"\"\n",
    "        self.connectedComponents = []\n",
    "        treated_nodes = {}\n",
    "        for i in self.nodes:\n",
    "            treated_nodes[i] = False\n",
    "        \n",
    "        for i in self.nodes:\n",
    "            if not treated_nodes[i]:\n",
    "                temp = []\n",
    "                self.DFS(i, treated_nodes, temp)\n",
    "                self.connectedComponents.append(temp)\n",
    "                \n",
    "        return self.connectedComponents\n",
    "    \n",
    "    def DFS(self, nodeId, treated_nodes, component):\n",
    "        component.append(nodeId)\n",
    "        treated_nodes[nodeId] = True\n",
    "\n",
    "        for j in self.nodes[nodeId].edges:\n",
    "            if not treated_nodes[j]:\n",
    "                self.DFS(j, treated_nodes, component)\n",
    "\n",
    "    \n",
    "    def connected_components_number(self):\n",
    "        if not self.connectedComponents:\n",
    "            self.connectedComponents = self.connected_components()\n",
    "        return len(self.connectedComponents)\n",
    "    \n",
    "    def graph_to_matrix(G):\n",
    "        matrix = []\n",
    "        for i in G.nodes:\n",
    "            ligne = [0 for i in range(len(G.nodes))]\n",
    "            for j in G.nodes[i].edges:\n",
    "                ligne[j] = G.nodes[i].edges[j]\n",
    "            matrix.append(ligne)\n",
    "        return matrix #np.array([m for m in matrix])\n",
    "            \n",
    "    def __str__(self):\n",
    "        graph = \"{\"\n",
    "        for node in self.nodes:\n",
    "            graph += str(self.nodes[node])+\"\\n\"\n",
    "        graph += \"}\"\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \"\"\"\n",
    "    A class used to represent a node\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    id : int\n",
    "        used to identify the node\n",
    "    topic : str\n",
    "        the topic of the article \n",
    "        represented by this node\n",
    "    tokens: list of str\n",
    "        list of the tokens of the article\n",
    "    edges: list of int\n",
    "        list of the nodes connected to this node\n",
    "        \n",
    "    Methods\n",
    "    -------\n",
    "    __str__()\n",
    "        returns the id of the node with the edges \n",
    "    \"\"\"\n",
    "    def __init__(self, id, topic, tokens):\n",
    "        self.id = id\n",
    "        self.topic = topic\n",
    "        self.tokens = list(tokens)\n",
    "        self.edges = {}\n",
    "        \n",
    "    def __str__(self):  \n",
    "        return \"{\" + str(self.id)+ \":\" + str(self.edges) + \"}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(node1, node2):\n",
    "    \"\"\"Finds the number of tokens shared by two nodes\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    node1, node2 : node\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int: number of tokens shared by the two nodes\n",
    "    \"\"\"\n",
    "    return len(list(set(node1.tokens) & set(node2.tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing HTML tags from the articles\n",
    "def remove_tags(text):\n",
    "    \"\"\"Remove HTML tags from a given text\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text: str\n",
    "        text to clean from html tags\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        : str\n",
    "        clean text\n",
    "    \"\"\"\n",
    "    TAG_RE = re.compile(r'<[^>]+>')\n",
    "    return TAG_RE.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set of functions used to clean a text and transform it to a list of tokens \n",
    "\n",
    "def extract_tokens(text):\n",
    "    \"\"\"Extracts tokens from a given text\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text: str\n",
    "        text to be splited to tokens\n",
    "    Returns\n",
    "    -------\n",
    "    res : list\n",
    "        list of tokens in the text\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        tmp_res = nltk.word_tokenize(sent)\n",
    "        for token in tmp_res:\n",
    "            res += re.split(\"[\\./]\", token)\n",
    "    return res\n",
    "\n",
    "\n",
    "def clean_tokens(tokens):\n",
    "    \"\"\"Removes punctuation marks from tokens\n",
    "    Parameters\n",
    "    ----------\n",
    "    tokens: list\n",
    "        list to be cleaned from punctuation marks\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list:\n",
    "        list cleaned from punctuation marks\n",
    "    \"\"\"\n",
    "    return [token.lower() for token in tokens if token not in string.punctuation]\n",
    "\n",
    "\n",
    "def remove_stop_words(tokens):\n",
    "    \"\"\"Removes stopwords from our tokens\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tokens: list \n",
    "        list of tokens to be cleaned from stopwords\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        :list\n",
    "        list cleaned from stopwords\n",
    "    \"\"\"\n",
    "    GARBAGE = {\"'s\", \"n't\", '...', 'oh',\"'m\", \"'re\", \"'\", \"''\", \"'ve\", \"'ll\", \"'d\", \"``\" }\n",
    "    STOP_WORDS = set(stopwords.words('english')).union(GARBAGE)\n",
    "    return [token for token in tokens if token not in STOP_WORDS]\n",
    "\n",
    "def text2tokens(text):\n",
    "    \"\"\"Used to combine three previous functions in one operation.\n",
    "    Parameters\n",
    "    ----------\n",
    "    Text: str\n",
    "        text to be cleaned\n",
    "    Returns\n",
    "    -------\n",
    "    tokens: list\n",
    "        list of tokens cleaned\n",
    "    \"\"\"\n",
    "    text = remove_tags(text)\n",
    "    tokens = extract_tokens(text)\n",
    "    tokens = clean_tokens(tokens)\n",
    "    tokens = remove_stop_words(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dataset\n",
    "df = pd.read_csv(\"dataset_business_technology_cybersecurity.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Software engineering</td>\n",
       "      <td>&lt;p&gt;&lt;b&gt;Software engineering&lt;/b&gt; is the systemat...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Company</td>\n",
       "      <td>&lt;p class=\"mw-empty-elt\"&gt;\\n&lt;/p&gt;\\n\\n&lt;p&gt;A &lt;b&gt;comp...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Misuse case</td>\n",
       "      <td>&lt;p&gt;&lt;b&gt;Misuse case&lt;/b&gt; is a business process mo...</td>\n",
       "      <td>cybersecurity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Processor design</td>\n",
       "      <td>&lt;p&gt;&lt;b&gt;Processor design&lt;/b&gt; is the design engin...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Automated attendant</td>\n",
       "      <td>&lt;p&gt;In telephony, an &lt;b&gt;automated attendant&lt;/b&gt;...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Growth platforms</td>\n",
       "      <td>&lt;p&gt;&lt;br&gt;&lt;b&gt;Growth platforms&lt;/b&gt; are specific in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Outline of finance</td>\n",
       "      <td>&lt;p&gt;The following outline is provided as an ove...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Unemployment</td>\n",
       "      <td>&lt;p&gt;&lt;b&gt;Unemployment&lt;/b&gt;, according to the OECD ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title                                            content  \\\n",
       "114  Software engineering  <p><b>Software engineering</b> is the systemat...   \n",
       "28                Company  <p class=\"mw-empty-elt\">\\n</p>\\n\\n<p>A <b>comp...   \n",
       "285           Misuse case  <p><b>Misuse case</b> is a business process mo...   \n",
       "111      Processor design  <p><b>Processor design</b> is the design engin...   \n",
       "169   Automated attendant  <p>In telephony, an <b>automated attendant</b>...   \n",
       "46       Growth platforms  <p><br><b>Growth platforms</b> are specific in...   \n",
       "80     Outline of finance  <p>The following outline is provided as an ove...   \n",
       "56           Unemployment  <p><b>Unemployment</b>, according to the OECD ...   \n",
       "\n",
       "             topic  \n",
       "114     technology  \n",
       "28        business  \n",
       "285  cybersecurity  \n",
       "111     technology  \n",
       "169     technology  \n",
       "46        business  \n",
       "80        business  \n",
       "56        business  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokens\"] = df[\"content\"].apply(lambda s: text2tokens(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a graph using articles as nodes\n",
    "G = Graph()\n",
    "for index, article in df.iterrows():\n",
    "    G.add_node(Node(index, article[\"topic\"], article[\"tokens\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding edges between each two nodes if they share 100 tokens\n",
    "G.add_edges(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing connected components\n",
    "connected_components = G.connected_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 12, 13, 16, 17, 15, 18, 19, 20, 21, 22, 23, 25, 24, 29, 27, 28, 30, 31, 32, 33, 34, 35, 37, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 64, 62, 65, 60, 67, 66, 68, 69, 72, 70, 71, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 63, 174, 91, 92, 93, 94, 95, 90, 98, 96, 97, 99, 100, 101, 103, 104, 105, 106, 107, 108, 102, 110, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 167, 170, 169, 172, 171, 179, 173, 176, 180, 175, 181, 178, 182, 183, 177, 184, 185, 186, 187, 188, 190, 189, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 229, 228, 231, 230, 232, 233, 234, 235, 236, 245, 240, 241, 242, 243, 251, 244, 252, 246, 254, 250, 259, 255, 256, 258, 260, 261, 262, 239, 298, 26, 157, 247, 291, 264, 265, 263, 269, 253, 271, 266, 267, 268, 270, 272, 273, 275, 276, 278, 277, 279, 280, 281, 282, 283, 285, 286, 284, 289, 287, 295, 288, 301, 302, 296, 306, 293, 310, 300, 314, 299, 315, 304, 305, 308, 311, 313, 309, 325, 317, 329, 330, 332, 292, 307, 316, 318, 319, 327, 331, 328, 303, 248, 320, 274, 238, 290]\n",
      "--------------------\n",
      "[1]\n",
      "--------------------\n",
      "[49]\n",
      "--------------------\n",
      "[61]\n",
      "--------------------\n",
      "[76]\n",
      "--------------------\n",
      "[130]\n",
      "--------------------\n",
      "[149]\n",
      "--------------------\n",
      "[156]\n",
      "--------------------\n",
      "[237]\n",
      "--------------------\n",
      "[249]\n",
      "--------------------\n",
      "[257]\n",
      "--------------------\n",
      "[294]\n",
      "--------------------\n",
      "[297]\n",
      "--------------------\n",
      "[312]\n",
      "--------------------\n",
      "[321]\n",
      "--------------------\n",
      "[322]\n",
      "--------------------\n",
      "[323]\n",
      "--------------------\n",
      "[324]\n",
      "--------------------\n",
      "[326]\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for component in  connected_components:\n",
    "    print(component)\n",
    "    print(\"--------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
